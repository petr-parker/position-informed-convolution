{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from model import PIC\n",
    "import yaml\n",
    "from easydict import EasyDict as edict\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import read_config\n",
    "cfg = read_config('configs/base_config.yaml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "77657\n"
     ]
    }
   ],
   "source": [
    "import dataset\n",
    "if cfg.DATASET == 'ImageNet_noise_reduction':\n",
    "    dataloader = dataset.ImageNet_noise_reduction(cfg)\n",
    "print(len(dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5, 5]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfg.WIENER_FRAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 8, kernel_size=3, stride=1, padding=1) # 1 входной канал, 32 выходных канала\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.maxpool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        self.conv2 = nn.Conv2d(8, 16, kernel_size=3, stride=1, padding=1)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.maxpool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(7*7*16, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.maxpool1(self.relu1(self.conv1(x)))\n",
    "        x = self.maxpool2(self.relu2(self.conv2(x)))\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc1(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "DEVICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SimpleCNN().to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "LEARNING_RATE = 0.001\n",
    "EPOCHS = 10\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training...\n",
      "Epoch [1/10] Loss: 0.1815\n",
      "Epoch [2/10] Loss: 0.0695\n",
      "Epoch [3/10] Loss: 0.0522\n",
      "Epoch [4/10] Loss: 0.0428\n",
      "Epoch [5/10] Loss: 0.0363\n",
      "Epoch [6/10] Loss: 0.0320\n",
      "Epoch [7/10] Loss: 0.0278\n",
      "Epoch [8/10] Loss: 0.0256\n",
      "Epoch [9/10] Loss: 0.0221\n",
      "Epoch [10/10] Loss: 0.0204\n",
      "Finished training...\n"
     ]
    }
   ],
   "source": [
    "print(\"Start training...\")\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()  # Set model to training mode\n",
    "    running_loss = 0.0\n",
    "    for batch_idx, (images, labels) in enumerate(train_loader):\n",
    "        images = images.to(DEVICE)\n",
    "        labels = labels.to(DEVICE)\n",
    "\n",
    "        # Обнуляем градиенты\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Прямой проход\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Обратный проход и оптимизация\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{EPOCHS}] Loss: {running_loss/len(train_loader):.4f}\")\n",
    "    running_loss = 0.0\n",
    "\n",
    "# 6. Оценка модели\n",
    "print(\"Finished training...\")   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on the test set: 98.81%\n",
      "End of experiment\n"
     ]
    }
   ],
   "source": [
    "model.eval()  # Set model to evaluation mode\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images = images.to(DEVICE)\n",
    "        labels = labels.to(DEVICE)\n",
    "\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)  # Get predicted classes\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f\"Accuracy on the test set: {100 * correct / total:.2f}%\")\n",
    "\n",
    "print(\"End of experiment\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimplePIC(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimplePIC, self).__init__()\n",
    "        self.pic1 = PIC(1, 8, 8, 3)\n",
    "        self.maxpool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        self.pic2 = PIC(8, 16, 16, 3)\n",
    "        self.maxpool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(7*7*16, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.maxpool1(self.pic1(x))\n",
    "        x = self.maxpool2(self.pic2(x))\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc1(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "pic = SimplePIC().to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "LEARNING_RATE = 0.001\n",
    "EPOCHS = 10\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(pic.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training...\n",
      "Epoch [1/10] Loss: 0.4506\n",
      "Epoch [2/10] Loss: 0.1310\n",
      "Epoch [3/10] Loss: 0.0914\n",
      "Epoch [4/10] Loss: 0.0742\n",
      "Epoch [5/10] Loss: 0.0634\n",
      "Epoch [6/10] Loss: 0.0563\n",
      "Epoch [7/10] Loss: 0.0510\n",
      "Epoch [8/10] Loss: 0.0471\n",
      "Epoch [9/10] Loss: 0.0434\n",
      "Epoch [10/10] Loss: 0.0407\n",
      "Finished training...\n"
     ]
    }
   ],
   "source": [
    "print(\"Start training...\")\n",
    "for epoch in range(EPOCHS):\n",
    "    pic.train()  # Set model to training mode\n",
    "    running_loss = 0.0\n",
    "    for batch_idx, (images, labels) in enumerate(train_loader):\n",
    "        images = images.to(DEVICE)\n",
    "        labels = labels.to(DEVICE)\n",
    "\n",
    "        # Обнуляем градиенты\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Прямой проход\n",
    "        outputs = pic(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Обратный проход и оптимизация\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{EPOCHS}] Loss: {running_loss/len(train_loader):.4f}\")\n",
    "    running_loss = 0.0\n",
    "\n",
    "# 6. Оценка модели\n",
    "print(\"Finished training...\")   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on the test set: 98.43%\n",
      "End of experiment\n"
     ]
    }
   ],
   "source": [
    "pic.eval()  # Set model to evaluation mode\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images = images.to(DEVICE)\n",
    "        labels = labels.to(DEVICE)\n",
    "\n",
    "        outputs = pic(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)  # Get predicted classes\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f\"Accuracy on the test set: {100 * correct / total:.2f}%\")\n",
    "\n",
    "print(\"End of experiment\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
